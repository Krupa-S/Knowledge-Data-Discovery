## Exercise 3.7.9
## Summer 2017

# 9. This question involves the use of multiple linear regression on the
# Auto data set.
# (a) Produce a scatterplot matrix which includes all of the variables
# in the data set.
# (b) Compute the matrix of correlations between the variables using
# the function cor(). You will need to exclude the name variable,
# cor()
# which is qualitative.
# (c) Use the lm() function to perform a multiple linear regression
# with mpg as the response and all other variables except name as
# the predictors. Use the summary() function to print the results.
# Comment on the output. For instance:
# i. Is there a relationship between the predictors and the response?
# ii. Which predictors appear to have a statistically significant
# relationship to the response?
# iii. What does the coefficient for the year variable suggest?
# (d) Use the plot() function to produce diagnostic plots of the linear
# regression fit. Comment on any problems you see with the fit.
# Do the residual plots suggest any unusually large outliers? Does
# the leverage plot identify any observations with unusually high
# leverage?
# (e) Use the * and : symbols to fit linear regression models with
# interaction effects. Do any interactions appear to be statistically
# significant?
# (f) Try a few different transformations of the variables, such as
# log(X), X, X^2. Comment on your findings.

## Load data

getwd()
auto=read.csv("Auto.csv", header=TRUE, na.strings="?")
auto=na.omit(auto)
dim(auto)
attach(auto)

# (a) Produce a scatterplot matrix which includes all of the variables
# in the data set.

pairs(auto)

# (b) Compute the matrix of correlations between the variables using
# the function cor(). You will need to exclude the name variable, cor() which is qualitative.

cor(subset(auto, select=-name))

# (c) Use the lm() function to perform a multiple linear regression
# with mpg as the response and all other variables except name as
# the predictors. Use the summary() function to print the results.

lm.fit=lm(mpg~.-name, data=auto)
summary(lm.fit)

# Comment on the output. For instance:
# i. Is there a relationship between the predictors and the response?

## Looking at the graph generated by the function pairs(auto), there are negative linear relationships 
## between mpg and displacement, horsepower, and weight respectively. 
## This negative linear relationship suggests that as displacement, horsepower, and weigth increase, the mpg value 
## decreases as a response.
## There is also a moderate positive linear relationshop between mpg and acceleration. As acceleration increases,
## the mpg increases as a response.

## Looking at the summary of the linear model of auto dataset, the Multiple R-squared attribute 
## has a value of 0.8215 which implies a moderate strong relationship between predictors and response. 
## In addition, the F-statistic has a value greater than 1 suggesting the alternative hypothesis is true that 
## there is a relationship between predictors and response.

# ii. Which predictors appear to have a statistically significant relationship to the response?

## Predictors cylinder, year, and origin appear to have a statistically significant relationship 
## to the mpg response as the Estimate and T-value are comparatively high, 
## and Std. Error and Pr(>|t|) value are low.

# iii. What does the coefficient for the year variable suggest?

## The Estimate measures the slope of the linear model. That is the average mpg value of a car 
## will increase by a factor of 0.750773 each year as new cars are getting more efficient at mpg.

## The Std. Erro measures the difference between actual and predicted mpg. This suggests that the 
## predicted mpg values can vary by 0.050973 mpg from their actual mpg values.

## The T-value measures how many standard deviations the estimate is away from 0. If the T-value 
## is far away from zero and comparatively larger than Std. Error, it could reject the null hypothesis 
## indicating a relatinoship between year and mpg exists.

## The Pr(>|t|) measures the probability of observing any value equal or larger than |t|. 
## A small p-value (less than 5% is usually good) for the intercept and the slope indicates that we can
## reject the null hypothesis to support that there is a relationship between year and mpg.

# (d) Use the plot() function to produce diagnostic plots of the linear
# regression fit. Comment on any problems you see with the fit.
# Do the residual plots suggest any unusually large outliers? Does
# the leverage plot identify any observations with unusually high leverage?


par(mfrow=c(2,2))
plot(lm.fit)
plot(predict(lm.fit), rstudent(lm.fit))



## The model plot seems to be inaccurate as the different curve parents are noticed in residual plot.
## For leverage plot, points are not of high magnitude residual. 
## The division of a residual by an estimate of its standard deviation is achieved by studentized residual plot. 
## These studentized plots helps to conclude that outliers of value greater than 3 are found.


# (e) Use the * and : symbols to fit linear regression models with
# interaction effects. Do any interactions appear to be statistically
# significant?

## cylinders:displacement + displacement:weight
summary(lm(mpg~cylinders:displacement+displacement:weight))

## cylinders + displacement + weight + cylinders:displacement + displacement:weight
summary(lm(mpg~cylinders*displacement+displacement*weight))

## Since, weight and diplacement and cylinders and displacement are highly co-related pairs of variables 
## according to co-relation matrix; these varaibles are used for idenifying the interactions effect.
## In the two way interation between the above mentioned pair; based on p-value the displacement and weigth 
## share statistically significant interaction while dispalcement and cylindefrs do not share significant 
## interaction.  

# (f) Try a few different transformations of the variables, such as
# log(X), a??X, X2. Comment on your findings.

## Original
summary(lm(mpg~year*origin), data=auto)

## Power of 2
summary(lm(mpg~I(year^2) * I(origin^2)), data=auto)

## Log of 10
summary(lm(mpg~log10(year)*log10(origin)), data=auto)

## Square root 
summary(lm(mpg~sqrt(year)*sqrt(origin)), data=auto)

## Findings
## The original non-linear model takes low correlation values Year and Origin with a low correlation value of
## 0.1843141 from correlation matrix cor(subset(auto, select=-name)). The small P-value for each variable are shown 
## with an F-statistic value of 171.6.
## The linear model showed improvement after variables have been transformed into power of 2, and both the P-value 
## and F-statistic has decreased. 
## However, as the variables are transformed to the Log10 and Square root, both P-value and F-statistics increases
## which downgraded the quality of the linear model. The further the F-statistic is from 1 the better the model is 
## when n > p. The smaller p-value and F-statistic indicates a stronger and clearer linear model.
